{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Computer: [PFC]\n",
      "Data directory: /home/elott1/data/packaged/\n",
      "Working directory: /home/elott1/code/NTdatasets/hartley/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "myhost = os.uname()[1]\n",
    "sys.path.insert(0, '/home/elott1/code/')\n",
    "data_dir = \"/home/elott1/data/packaged/\"\n",
    "work_dir = '/home/elott1/code/NTdatasets/hartley/'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device0 = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Running on Computer: [{myhost}]')\n",
    "print(f'Data directory: {data_dir}')\n",
    "print(f'Working directory: {work_dir}')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking __init__.py for NDNT.utils\n"
     ]
    }
   ],
   "source": [
    "# NDN tools\n",
    "import NDNT.utils as utils          # some other utilities\\n\",\n",
    "from NDNT.utils import imagesc      # because I'm lazy\\n\",\n",
    "from NDNT.utils import ss           # because I'm real lazy\\n\",\n",
    "import NDNT.NDNT as NDN\n",
    "from NDNT.modules.layers import *\n",
    "from NDNT.networks import *\n",
    "from NDNT.utils.DanUtils import ss\n",
    "from NDNT.utils.DanUtils import imagesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn0 = 'Jocamo_220628_full_HC_ETCC_nofix_v08'\n",
    "f = h5py.File(os.path.join(data_dir, fn0+'.mat'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "Stim: using laminar probe stimulus\n",
      "  Adding fixation point\n",
      "  Done\n",
      "T-range: 0 1000\n",
      "  Trimming experiment 36720->1000 time points based on eye_config and Tmax\n",
      "Extending final block at  960 1000\n"
     ]
    }
   ],
   "source": [
    "from NTdatasets.hartley.hartley import HartleyDataset\n",
    "\n",
    "expts = [fn0]\n",
    "\n",
    "data = HartleyDataset(\n",
    "    filenames=expts,\n",
    "    datadir=data_dir,\n",
    "    num_lags=1,\n",
    "    time_embed=False,\n",
    "    include_MUs=False,\n",
    "    preload=True,\n",
    "    drift_interval=None,\n",
    "    device=device0,\n",
    "    eye_config=3,\n",
    "    maxT=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36720, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs_pars = utils.create_optimizer_params(\n",
    "    optimizer_type='lbfgs',\n",
    "    tolerance_change=1e-10,\n",
    "    tolerance_grad=1e-10,\n",
    "    history_size=10,\n",
    "    batch_size=4000,\n",
    "    max_epochs=3,\n",
    "    max_iter = 2000,\n",
    "    device = device)\n",
    "\n",
    "data.add_covariate('metadata', np.array(data.metas)[:1000])\n",
    "data.metas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTreg0 = 1.0\n",
    "L1reg0 = 0.0001\n",
    "\n",
    "glm_all_par = NDNLayer.layer_dict( \n",
    "    input_dims=[1,1,1,data.metas.shape[1]], num_filters=data.NC, \n",
    "    bias=True, initialize_center = True,\n",
    "    NLtype='softplus')\n",
    "glm_all_par['reg_vals'] = {'d2xt': XTreg0, 'l1':L1reg0, 'localx':0.001, 'bcs':{'d2xt':1}  } \n",
    "\n",
    "glm_net = FFnetwork.ffnet_dict(xstim_n='metadata', layer_list=[glm_all_par])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.39706039e-03 -7.16829300e-03 -8.72731209e-02 -5.32166958e-02\n",
      " -3.32930088e-01 -4.88505363e-02 -8.62479210e-04 -1.03735924e-03\n",
      " -1.61218643e-03 -4.57360744e-02 -4.16898727e-02  1.13081932e-03\n",
      " -1.81570053e-02 -8.71174335e-02 -1.86923742e-01 -4.83293533e-02\n",
      "  9.62805748e-03 -1.24532700e-01 -1.43420887e+00 -1.74955368e-01\n",
      " -7.92806149e-02 -8.35585594e-03 -1.09011889e-01  6.88982010e-03\n",
      " -1.78129673e-01 -1.87892914e-02 -9.65437889e-02  6.33955002e-04\n",
      " -3.09023857e-02 -1.12953901e-01 -6.74123764e-02 -3.62658501e-03\n",
      " -1.90558195e-01  7.40289688e-04 -1.09565258e-02 -5.76720238e-02\n",
      " -7.32498169e-02 -1.04814529e-01 -6.63280487e-03 -5.28273582e-02\n",
      " -2.21951008e-02             inf -1.16327524e-01 -1.82256699e-02\n",
      " -3.91426086e-02 -2.58633614e-01 -3.58042717e-02 -1.45932436e-01\n",
      "  3.57737541e-02 -1.37591362e-03 -5.54707050e-02  1.25336647e-03\n",
      " -1.90668106e-02 -7.60300159e-02 -2.33979225e-02 -3.69838047e+00\n",
      " -5.70478439e-02 -3.91149521e-03 -1.09751701e-01  9.02175903e-03\n",
      " -1.60217762e-01 -2.09318399e-01 -4.13970947e-02 -5.34479618e-02\n",
      " -2.28786469e-03 -1.90236568e-02 -6.67378902e-02  5.69462776e-03\n",
      " -9.42373276e-03 -5.59644699e-02  8.93449783e-03 -1.62938356e-01\n",
      " -4.38103676e-02 -2.20608711e-02 -2.24732876e-01 -2.09829807e-02\n",
      " -8.39853287e-03 -6.56995773e-02 -8.42809677e-03 -1.01428032e-02\n",
      " -5.25426865e-03 -2.93188095e-02 -5.04432201e-01             inf\n",
      " -1.97581768e-01 -1.67196274e-01  5.49602509e-02 -4.02702808e-01\n",
      " -2.92965889e-01 -4.16769981e-02 -2.48057842e-02 -8.29133987e-02\n",
      " -3.29234600e-02 -1.77240372e-03 -6.01077080e-03 -2.24828720e-03\n",
      " -2.54440308e-01 -1.26588345e-02 -2.30813026e-03 -4.26506996e-02\n",
      "  3.27479839e-02 -6.70433044e-03 -1.52950287e-02 -1.17847919e-02\n",
      "             inf -3.19828987e-02 -1.40412331e-01 -1.19020939e-02\n",
      "  5.24520874e-06 -3.84536028e-01 -1.84328556e-02 -1.39442921e-01\n",
      " -1.71728134e-02 -8.82573128e-02 -5.70983887e-02 -2.49129057e-01\n",
      " -1.25520229e-02 -2.47617483e-01 -4.43549156e-02  1.10983849e-02\n",
      " -6.97898865e-02 -2.21999884e-01 -1.93586349e-02 -8.81912708e-02\n",
      " -6.15923405e-02 -1.99388504e-01 -1.02022886e-02 -2.23008156e-01\n",
      " -9.81507301e-02 -1.78389549e-02 -2.98254490e-02 -6.45072460e-02\n",
      " -2.80277729e-02  6.27899170e-03 -2.99477577e-03 -4.90604639e-02\n",
      " -1.34804010e-01  5.69725037e-03 -4.80318069e-03 -2.18663216e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elott1/code/NDNT/NDNT.py:732: RuntimeWarning: divide by zero encountered in log\n",
      "  LLnulls = np.log(rbar)-1\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "## Fit all GLMs at once -- example for choice of regularization above\n",
    "glm_all = NDN.NDN(ffnet_list=[glm_net])\n",
    "glm_all.fit(data, force_dict_training=True, **lbfgs_pars, verbose=0)\n",
    "LLs = glm_all.eval_models(data[data.val_inds], null_adjusted=True)\n",
    "print(LLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Reset cells_out to full dataset (140 cells).\n",
      "   0.00        inf  -0.0868900\n",
      "   0.00        inf  -0.0873508\n",
      "   0.01        inf  -0.0244875\n",
      "   0.03        inf  -0.0879474\n",
      "   0.10        inf  -0.0705743\n",
      "   0.30        inf  -0.0402524\n",
      "   1.00        inf  -0.0566220\n",
      "   3.00        inf  -0.1576395\n",
      "  10.00        inf  -0.0852189\n",
      "  30.00        inf  -0.1142206\n",
      " 100.00        inf  -0.1307681\n",
      " 300.00        inf  -0.1115551\n"
     ]
    }
   ],
   "source": [
    "## Optimize d2xt regularization\n",
    "reglist = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]\n",
    "LLsR = np.zeros([len(reglist), data.NC])\n",
    "data.set_cells()\n",
    "for rr in range(len(reglist)):\n",
    "    glm_all_par['reg_vals']['d2xt'] = reglist[rr]\n",
    "    glm_iter = NDN.NDN(ffnet_list=[glm_net])\n",
    "    glm_iter.fit(data, force_dict_training=True, **lbfgs_pars, verbose=0)\n",
    "    LLsR[rr, :] = glm_iter.eval_models(data[data.val_inds], null_adjusted=True)\n",
    "    print( \"%7.2f  %9.7f  %9.7f\"%(reglist[rr], np.mean(LLsR[rr,:]), LLsR[rr, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLs0 = np.max(np.mean(LLsR, axis=1))\n",
    "LLs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
